{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9d37bf",
   "metadata": {},
   "source": [
    "# Workflow for the Backmapping method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0104ff",
   "metadata": {},
   "source": [
    "<img src=\"bcml.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60021f18",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca7b6f",
   "metadata": {},
   "source": [
    "* <a href='#a'> Import the needed libraries for the task </a>\n",
    "* <a href='#pre-processing'> Pre-processing \n",
    "    - <a href='#c'> Load the chemical structure of the system </a>\n",
    "    - <a href='#d'> Load the trajectory file </a>\n",
    "    - <a href='#e'> Compute the number of particles per chain  </a>\n",
    "    - <a href='#g'> Compute the bond vectors for each monomer type  </a>\n",
    "    - <a href='#h'> Define the function that generates the target and input of the CNN  </a>\n",
    "    - <a href='#f'> Create CNN input and target output for a test-set configuration  </a>\n",
    "* <a href='#training-process'> Backmapping by utilizing the trained CNN    \n",
    "   * <a href='#j'> Load the data </a>\n",
    "   * <a href='#i'> Develop the conditional convolutional neural network  </a>\n",
    "   * <a href='#l'> Decoding process  </a>\n",
    "    - <a href='#m'> Decoding the output of the neural network for each CG type </a>\n",
    "    - <a href='#n'> Get the structure of each chain </a>\n",
    "    - <a href='#o'> Re-insert atomic detail to CG congigurations via the trained CNN </a>\n",
    "   * <a href='#p'> Prediction of an atomistic configuration from a given CG configuration  </a> \n",
    "* <a href='#q'> Visualize the results </a>\n",
    "    - <a href='#r'> Generate the distribution plots for bond lengths, bond angles and dihedral angles </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad4f90",
   "metadata": {},
   "source": [
    "# Import the needed libraries for this task  <span id='a'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0872ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import mdtraj as md\n",
    "from params import *\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from post_processing import plot_dists\n",
    "# turn off the warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import multiprocessing\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.config.experimental.set_synchronous_execution(enable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1773e5c",
   "metadata": {},
   "source": [
    "# Pre-processing <span id='pre-processing'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bfb733",
   "metadata": {},
   "source": [
    "### Load the chemical structure of the system <span id='c'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5535eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Monomers per chain: 100\n"
     ]
    }
   ],
   "source": [
    "with open('./sequence_copolymer_45mer') as f1:\n",
    "     lines = (line for line in f1 if not line.startswith('#'))\n",
    "     chemistry = np.loadtxt(lines, delimiter=' ',skiprows=0,usecols = (0),dtype=(\"str\"))  \n",
    "\n",
    "print(\"Number of Monomers per chain:\",chemistry.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23737d70",
   "metadata": {},
   "source": [
    "### Load the trajectory file <span id='d'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6490ce7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mdtraj.Trajectory with 1851 frames, 11562 atoms, 96 residues, and unitcells>\n"
     ]
    }
   ],
   "source": [
    "t = md.load('../Data/traj_copo45perc_5000frames.gro')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec906b",
   "metadata": {},
   "source": [
    "### Compute the bond vectors for each monomer type  <span id='g'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5d7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLS_vectors(index,tar_list,Coord):\n",
    "    b1=Coord[5+index]-Coord[index]\n",
    "    b2=Coord[1+index]-Coord[index]\n",
    "    b3=Coord[3+index]-Coord[1+index]\n",
    "    b4=Coord[2+index]-Coord[1+index]\n",
    "    b5=Coord[4+index]-Coord[2+index]\n",
    "    b6=Coord[6+index]-Coord[2+index]\n",
    "    b7=Coord[7+index]-Coord[6+index]\n",
    "    b8=Coord[8+index]-Coord[6+index]\n",
    "    b9=Coord[9+index]-Coord[6+index]\n",
    "    b10=Coord[10+index]-Coord[2+index]\n",
    "   \n",
    "    tar_list.append([b1[0],b1[1],b1[2]])\n",
    "    tar_list.append([b2[0],b2[1],b2[2]])\n",
    "    tar_list.append([b3[0],b3[1],b3[2]])      \n",
    "    tar_list.append([b4[0],b4[1],b4[2]])\n",
    "    tar_list.append([b5[0],b5[1],b5[2]])\n",
    "    tar_list.append([b6[0],b6[1],b6[2]])\n",
    "    tar_list.append([b7[0],b7[1],b7[2]])      \n",
    "    tar_list.append([b8[0],b8[1],b8[2]])\n",
    "    tar_list.append([b9[0],b9[1],b9[2]])\n",
    "    tar_list.append([b10[0],b10[1],b10[2]])\n",
    " \n",
    "    return      \n",
    "\n",
    "\n",
    "def SLM_vectors(index,tar_list,Coord):\n",
    "    b1=Coord[1+index]-Coord[index]\n",
    "    b2=Coord[3+index]-Coord[1+index]\n",
    "    b3=Coord[2+index]-Coord[1+index]\n",
    "    b4=Coord[4+index]-Coord[2+index]\n",
    "    b5=Coord[5+index]-Coord[2+index]\n",
    "    b6=Coord[6+index]-Coord[5+index]\n",
    "    b7=Coord[7+index]-Coord[5+index]\n",
    "    b8=Coord[8+index]-Coord[5+index]\n",
    "    b9=Coord[9+index]-Coord[2+index]\n",
    "   \n",
    "    tar_list.append([b1[0],b1[1],b1[2]])\n",
    "    tar_list.append([b2[0],b2[1],b2[2]])\n",
    "    tar_list.append([b3[0],b3[1],b3[2]])      \n",
    "    tar_list.append([b4[0],b4[1],b4[2]])\n",
    "    tar_list.append([b5[0],b5[1],b5[2]])\n",
    "    tar_list.append([b6[0],b6[1],b6[2]])\n",
    "    tar_list.append([b7[0],b7[1],b7[2]])      \n",
    "    tar_list.append([b8[0],b8[1],b8[2]])\n",
    "    tar_list.append([b9[0],b9[1],b9[2]])\n",
    "  \n",
    "    return      \n",
    "\n",
    "def SLE_vectors(index,tar_list,Coord):\n",
    "    b1=Coord[1+index]-Coord[index]\n",
    "    b2=Coord[3+index]-Coord[1+index]\n",
    "    b3=Coord[2+index]-Coord[1+index]\n",
    "    b4=Coord[4+index]-Coord[2+index]\n",
    "    b5=Coord[5+index]-Coord[2+index]\n",
    "    b6=Coord[6+index]-Coord[5+index]\n",
    "    b7=Coord[7+index]-Coord[2+index]\n",
    "    b8=Coord[8+index]-Coord[7+index]\n",
    "    b9=Coord[9+index]-Coord[7+index]\n",
    "    b10=Coord[10+index]-Coord[7+index]\n",
    "  \n",
    "    tar_list.append([b1[0],b1[1],b1[2]])\n",
    "    tar_list.append([b2[0],b2[1],b2[2]])\n",
    "    tar_list.append([b3[0],b3[1],b3[2]])      \n",
    "    tar_list.append([b4[0],b4[1],b4[2]])\n",
    "    tar_list.append([b5[0],b5[1],b5[2]])\n",
    "    tar_list.append([b6[0],b6[1],b6[2]])\n",
    "    tar_list.append([b7[0],b7[1],b7[2]])      \n",
    "    tar_list.append([b8[0],b8[1],b8[2]])\n",
    "    tar_list.append([b9[0],b9[1],b9[2]])\n",
    "    tar_list.append([b10[0],b10[1],b10[2]])\n",
    "\n",
    "    return      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe2dbf",
   "metadata": {},
   "source": [
    "### Define the function that generates the target and input of the CNN <span id='h'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c41b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(frames,save_path):  \n",
    " input_file=[]\n",
    " target_file=[]  \n",
    " for frame_number, frameIndx in enumerate(frames):\n",
    "    LXX,LYY,LZZ=t.unitcell_lengths[frameIndx][0],t.unitcell_lengths[frameIndx][1],t.unitcell_lengths[frameIndx][2]\n",
    "    hLXX,hLYY,hLZZ=LXX/2.0,LYY/2.0,LZZ/2.0\n",
    "    Coord=np.zeros([npart,3],dtype=np.float32)\n",
    "    frame_counter_1 = -1\n",
    "    frame_counter_2 = 0\n",
    "    for j in range(nchain):\n",
    "        comx,comy,comz=0.0,0.0,0.0\n",
    "        coordCG=np.zeros([nmer,3],dtype=np.float32)\n",
    "        imageCG=np.zeros([nmer,3],dtype=np.float32)\n",
    "        inp_list = []\n",
    "        tar_list = []\n",
    "        \n",
    "        for jj in range(nmer):\n",
    "            posCM=[0.,0.,0.]\n",
    "            if(jj==0): masses,merlen = masses_SLS,merlen_SLS\n",
    "            elif(jj==nmer-1): masses,merlen = masses_SLE,merlen_SLE\n",
    "            else: masses,merlen = masses_SLM,merlen_SLM\n",
    "            totmass=np.sum(masses)\n",
    "            for ii in range(merlen):\n",
    "                frame_counter_1 += 1\n",
    "                partIndx = frame_counter_1\n",
    "                Coord[partIndx]=t.xyz[frameIndx,(partIndx),:]\n",
    "                if (jj!=0 or ii!=0):\n",
    "                    if(Coord[partIndx][0]-Coord[partIndx-1][0]<-hLXX): Coord[partIndx][0]+=LXX\n",
    "                    if(Coord[partIndx][0]-Coord[partIndx-1][0]>hLXX): Coord[partIndx][0]-=LXX\n",
    "                    if(Coord[partIndx][1]-Coord[partIndx-1][1]<-hLYY): Coord[partIndx][1]+=LYY\n",
    "                    if(Coord[partIndx][1]-Coord[partIndx-1][1]>hLYY): Coord[partIndx][1]-=LYY\n",
    "                    if(Coord[partIndx][2]-Coord[partIndx-1][2]<-hLZZ): Coord[partIndx][2]+=LZZ\n",
    "                    if(Coord[partIndx][2]-Coord[partIndx-1][2]>hLZZ): Coord[partIndx][2]-=LZZ\n",
    "\n",
    "                posCM[0]+=Coord[partIndx][0]*masses[ii]\n",
    "                posCM[1]+=Coord[partIndx][1]*masses[ii]\n",
    "                posCM[2]+=Coord[partIndx][2]*masses[ii]\n",
    "\n",
    "            posCM[0]/=totmass\n",
    "            posCM[1]/=totmass\n",
    "            posCM[2]/=totmass\n",
    "            coordCG[jj]=posCM[:]\n",
    "        \n",
    "        for jj in range(nmer):\n",
    "            if(jj==0):\n",
    "                merlen = merlen_SLS\n",
    "                SLS_vectors(frame_counter_2,tar_list,Coord)\n",
    "            elif(jj==nmer-1): \n",
    "                merlen = merlen_SLE\n",
    "                SLE_vectors(frame_counter_2,tar_list,Coord)\n",
    "            else:\n",
    "                merlen = merlen_SLM  \n",
    "                SLM_vectors(frame_counter_2,tar_list,Coord)\n",
    "            imageCG[jj] = [coordCG[jj][0],coordCG[jj][1],coordCG[jj][2]]\n",
    "            frame_counter_2 += merlen\n",
    "\n",
    "        tar_list = np.array(tar_list,dtype=np.float64)                \n",
    "        nimages = int(np.ceil((tar_list.shape[0])/IMG_WIDTH))  \n",
    "        s = int(np.ceil(nmer/nimages)) \n",
    "        meridx = [(s*(h+1)-1) for h in range(nimages)]\n",
    "        meridx.pop(-1)\n",
    "        meridx.append(nmer-1)\n",
    "        AT = []\n",
    "        CG = []\n",
    "        frame_counter = -1\n",
    "        arrAT = np.zeros([IMG_WIDTH,3],dtype=np.float64)\n",
    "        arrCG = np.zeros([IMG_WIDTH,7],dtype=np.float64)\n",
    "        c = -1\n",
    "        for jj in range(nmer):\n",
    "            if(jj==0): \n",
    "                dtseg = spots_SLS\n",
    "                m_id = [0,0,0,1]\n",
    "            elif(jj==nmer-1):\n",
    "                dtseg = spots_SLE\n",
    "                m_id = [1,0,0,0]\n",
    "            elif chemistry[jj]==\"L\":\n",
    "                dtseg = spots_SLM\n",
    "                m_id = [0,1,0,0]\n",
    "            elif chemistry[jj]==\"D\":\n",
    "                dtseg = spots_SLM\n",
    "                m_id = [0,0,1,0]\n",
    "            for g in range(dtseg):\n",
    "                frame_counter += 1\n",
    "                AT.append([tar_list[frame_counter][0],tar_list[frame_counter][1],tar_list[frame_counter][2]])\n",
    "                CG.append([imageCG[jj][0],imageCG[jj][1],imageCG[jj][2],m_id[0],m_id[1],m_id[2]])\n",
    " \n",
    "            if jj in meridx: \n",
    "                c += 1\n",
    "                AT = np.array(AT,dtype=np.float64)\n",
    "                CG = np.array(CG,dtype=np.float64)\n",
    "                shiftx = 60\n",
    "                arrAT[shiftx:shiftx+int(AT.shape[0])] = AT[:]\n",
    "                arrCG[shiftx:shiftx+int(CG.shape[0])] = CG[:]  \n",
    "                input_file.append(arrCG)\n",
    "                target_file.append(arrAT)                \n",
    "                AT = []\n",
    "                CG = []\n",
    "                arrAT = np.zeros([IMG_WIDTH,3],dtype=np.float64)\n",
    "                arrCG = np.zeros([IMG_WIDTH,7],dtype=np.float64)\n",
    "                \n",
    " final_input=np.array(input_file,dtype=np.float64)\n",
    " final_target=np.array(target_file,dtype=np.float64) \n",
    " print(final_input.shape, final_target.shape)      \n",
    " print(final_target.min(),final_target.max())\n",
    " with open(save_path+'_input.pkl','wb') as f:\n",
    "     pickle.dump(final_input, f)\n",
    "\n",
    " with open(save_path+'_target.pkl','wb') as f:\n",
    "     pickle.dump(final_target, f)        \n",
    " input_file = []\n",
    " target_file = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a2227",
   "metadata": {},
   "source": [
    "### Create CNN inputs and target outputs for a test-set configuration <span id='f'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "150d7eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (96, 128, 6)\n",
      "Target output shape: (96, 128, 3)\n",
      "Create CNN input and target output for configuration: 525\n"
     ]
    }
   ],
   "source": [
    "random.seed(100)\n",
    "frames = random.sample(range(len(com_list)), len(com_list))\n",
    "\n",
    "# Test configuration\n",
    "test_frame = frames[0]\n",
    "\n",
    "# Choose a configuration of the test-set\n",
    "save_path=\"test\" \n",
    "encoding([test_frame],save_path) \n",
    "\n",
    "print(\"Create CNN input and target output for configuration:\",test_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac82fd67",
   "metadata": {},
   "source": [
    "# Backmapping by utilizing the trained CNN   <span id='training-process'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b105cb9",
   "metadata": {},
   "source": [
    "### Load the data <span id='j'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8450969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target output for a single configuration: (96, 128, 3)\n",
      "Shape of input for a single configuration: (96, 128, 6)\n",
      "Number of samples: 96\n"
     ]
    }
   ],
   "source": [
    "with open('./test_target.pkl','rb') as f:\n",
    "    test_target = pickle.load(f)\n",
    "    print(\"Shape of target output for a single configuration:\",test_target.shape)    \n",
    "\n",
    "with open('./test_input.pkl','rb') as f:\n",
    "    test_input = pickle.load(f)\n",
    "    print(\"Shape of input for a single configuration:\",test_input.shape)        \n",
    "\n",
    "print(\"Number of samples:\",test_input.shape[0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad1e56",
   "metadata": {},
   "source": [
    "### Develop the conditional convolutional neural network  <span id='i'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c6827d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "def downsample(entered_input,filters, size, apply_batchnorm=True,strides=2):\n",
    "  conv1 = tf.keras.layers.Conv1D(filters, size, strides=strides, padding='same',use_bias=False)(entered_input)\n",
    "  conv1 = tf.keras.layers.LeakyReLU()(conv1)\n",
    "  \n",
    "  if apply_batchnorm:\n",
    "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "  \n",
    "  \n",
    "\n",
    "  return conv1\n",
    "\n",
    "\n",
    "def upsample(entered_input,filters, size, skip_layer, apply_dropout=False, strides=2, apply_skip=True):\n",
    "  tran1 = tf.keras.layers.Conv1DTranspose(filters, size, strides=strides,\n",
    "                                    padding='same',\n",
    "                                    use_bias=True)(entered_input)\n",
    "  tran1 = tf.keras.layers.ReLU()(tran1) \n",
    "  if apply_dropout:\n",
    "      tran1 = tf.keras.layers.Dropout(0.5)(tran1)\n",
    "  \n",
    "  if apply_skip:\n",
    "      tran1 = tf.keras.layers.Concatenate()([tran1,skip_layer])\n",
    "  return tran1\n",
    "\n",
    "\n",
    "def Generator(): \n",
    "  input1 = tf.keras.layers.Input([1024,7])  \n",
    "  output1 = downsample(input1, 64, 3)\n",
    "  output2 = downsample(output1, 128, 3)\n",
    "  output3 = downsample(output2, 256, 3)  \n",
    "  output4 = downsample(output3, 512, 3) \n",
    "  output5 = downsample(output4, 512, 3) \n",
    "\n",
    "  output = upsample(output5, 512, 3, output4, apply_dropout=True)\n",
    "  output = upsample(output, 256, 3, output3, apply_dropout=False)\n",
    "  output = upsample(output, 128, 3, output2, apply_dropout=False)\n",
    "  output = upsample(output, 64, 3, output1, apply_dropout=False)\n",
    "  \n",
    "  output = tf.keras.layers.Conv1DTranspose(64, 3, strides=2, padding=\"same\",  activation=\"relu\")(output)\n",
    "  out = tf.keras.layers.Conv1DTranspose(3, 3, strides=1, padding=\"same\",  activation=\"tanh\")(output)\n",
    "\n",
    "  model = tf.keras.models.Model(input1,out)\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf9e5d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1024, 7)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 512, 64)      1344        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 512, 64)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 64)      256         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 256, 128)     24576       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 256, 128)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 128)     512         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 128, 256)     98304       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 128, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 256)     1024        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 64, 512)      393216      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 64, 512)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 512)      2048        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 32, 512)      786432      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 32, 512)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 512)      2048        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose (Conv1DTranspo (None, 64, 512)      786944      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 64, 512)      0           conv1d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 512)      0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 1024)     0           dropout[0][0]                    \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTrans (None, 128, 256)     786688      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128, 256)     0           conv1d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 512)     0           re_lu_1[0][0]                    \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTrans (None, 256, 128)     196736      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 256, 128)     0           conv1d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256)     0           re_lu_2[0][0]                    \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTrans (None, 512, 64)      49216       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 512, 64)      0           conv1d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 128)     0           re_lu_3[0][0]                    \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_4 (Conv1DTrans (None, 1024, 64)     24640       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_5 (Conv1DTrans (None, 1024, 3)      579         conv1d_transpose_4[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 3,154,563\n",
      "Trainable params: 3,151,619\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gen = Generator()\n",
    "model_gen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faad728",
   "metadata": {},
   "source": [
    "# Decoding process <span id='l'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ebe52",
   "metadata": {},
   "source": [
    "### Decoding the output of the neural network for each CG type <span id='m'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22659928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLS_d(pvecs,iosx,iosy,iosz,Coords,global_count):\n",
    "     b_vec = np.zeros([9,3])          \n",
    "     b_vec[:] = pvecs\n",
    "     v_vec = np.zeros([10,3])\n",
    "     \n",
    "     masses = masses_SLS\n",
    "     totmass = sum(masses)\n",
    "        \n",
    "     v_vec[0,0] = -((b_vec[0,0])*masses[5]+(b_vec[1,0])*masses[1]+(b_vec[1,0]+b_vec[2,0])*masses[3]+(b_vec[1,0]+b_vec[3,0])*masses[2]+(b_vec[1,0]+b_vec[3,0]+b_vec[4,0])*masses[4]+(b_vec[1,0]+b_vec[3,0]+b_vec[5,0])*masses[6]+(b_vec[1,0]+b_vec[3,0]+b_vec[5,0]+b_vec[6,0])*masses[7]+(b_vec[1,0]+b_vec[3,0]+b_vec[5,0]+b_vec[7,0])*masses[8]+(b_vec[1,0]+b_vec[3,0]+b_vec[5,0]+b_vec[8,0])*masses[9])/totmass  \n",
    "     v_vec[0,1] = -((b_vec[0,1])*masses[5]+(b_vec[1,1])*masses[1]+(b_vec[1,1]+b_vec[2,1])*masses[3]+(b_vec[1,1]+b_vec[3,1])*masses[2]+(b_vec[1,1]+b_vec[3,1]+b_vec[4,1])*masses[4]+(b_vec[1,1]+b_vec[3,1]+b_vec[5,1])*masses[6]+(b_vec[1,1]+b_vec[3,1]+b_vec[5,1]+b_vec[6,1])*masses[7]+(b_vec[1,1]+b_vec[3,1]+b_vec[5,1]+b_vec[7,1])*masses[8]+(b_vec[1,1]+b_vec[3,1]+b_vec[5,1]+b_vec[8,1])*masses[9])/totmass   \n",
    "     v_vec[0,2] = -((b_vec[0,2])*masses[5]+(b_vec[1,2])*masses[1]+(b_vec[1,2]+b_vec[2,2])*masses[3]+(b_vec[1,2]+b_vec[3,2])*masses[2]+(b_vec[1,2]+b_vec[3,2]+b_vec[4,2])*masses[4]+(b_vec[1,2]+b_vec[3,2]+b_vec[5,2])*masses[6]+(b_vec[1,2]+b_vec[3,2]+b_vec[5,2]+b_vec[6,2])*masses[7]+(b_vec[1,2]+b_vec[3,2]+b_vec[5,2]+b_vec[7,2])*masses[8]+(b_vec[1,2]+b_vec[3,2]+b_vec[5,2]+b_vec[8,2])*masses[9])/totmass  \n",
    "  \n",
    "     v_vec[5,0] = v_vec[0,0] + b_vec[0,0]\n",
    "     v_vec[5,1] = v_vec[0,1] + b_vec[0,1]\n",
    "     v_vec[5,2] = v_vec[0,2] + b_vec[0,2]\n",
    "     \n",
    "     v_vec[1,0] = v_vec[0,0] + b_vec[1,0]\n",
    "     v_vec[1,1] = v_vec[0,1] + b_vec[1,1]\n",
    "     v_vec[1,2] = v_vec[0,2] + b_vec[1,2]\n",
    "     \n",
    "     v_vec[3,0] = v_vec[1,0] + b_vec[2,0]\n",
    "     v_vec[3,1] = v_vec[1,1] + b_vec[2,1]\n",
    "     v_vec[3,2] = v_vec[1,2] + b_vec[2,2]\n",
    "     \n",
    "     v_vec[2,0] = v_vec[1,0] + b_vec[3,0]\n",
    "     v_vec[2,1] = v_vec[1,1] + b_vec[3,1]\n",
    "     v_vec[2,2] = v_vec[1,2] + b_vec[3,2]\n",
    "     \n",
    "     v_vec[4,0] = v_vec[2,0] + b_vec[4,0]\n",
    "     v_vec[4,1] = v_vec[2,1] + b_vec[4,1]\n",
    "     v_vec[4,2] = v_vec[2,2] + b_vec[4,2]\n",
    "          \n",
    "     v_vec[6,0] = v_vec[2,0] + b_vec[5,0]\n",
    "     v_vec[6,1] = v_vec[2,1] + b_vec[5,1]\n",
    "     v_vec[6,2] = v_vec[2,2] + b_vec[5,2]\n",
    "        \n",
    "     v_vec[7,0] = v_vec[6,0] + b_vec[6,0]\n",
    "     v_vec[7,1] = v_vec[6,1] + b_vec[6,1]\n",
    "     v_vec[7,2] = v_vec[6,2] + b_vec[6,2]\n",
    "\n",
    "     v_vec[8,0] = v_vec[6,0] + b_vec[7,0]\n",
    "     v_vec[8,1] = v_vec[6,1] + b_vec[7,1]\n",
    "     v_vec[8,2] = v_vec[6,2] + b_vec[7,2]\n",
    "\n",
    "     v_vec[9,0] = v_vec[6,0] + b_vec[8,0]\n",
    "     v_vec[9,1] = v_vec[6,1] + b_vec[8,1]\n",
    "     v_vec[9,2] = v_vec[6,2] + b_vec[8,2]\n",
    "\n",
    "\n",
    "     Coords[global_count][:] = [iosx+v_vec[0,0],iosy+v_vec[0,1],iosz+v_vec[0,2]]\n",
    "     Coords[global_count+1][:] = [iosx+v_vec[1,0],iosy+v_vec[1,1],iosz+v_vec[1,2]]\n",
    "     Coords[global_count+2][:] = [iosx+v_vec[2,0],iosy+v_vec[2,1],iosz+v_vec[2,2]]\n",
    "     Coords[global_count+3][:] = [iosx+v_vec[3,0],iosy+v_vec[3,1],iosz+v_vec[3,2]]\n",
    "     Coords[global_count+4][:] = [iosx+v_vec[4,0],iosy+v_vec[4,1],iosz+v_vec[4,2]]\n",
    "     Coords[global_count+5][:] = [iosx+v_vec[5,0],iosy+v_vec[5,1],iosz+v_vec[5,2]]\n",
    "     Coords[global_count+6][:] = [iosx+v_vec[6,0],iosy+v_vec[6,1],iosz+v_vec[6,2]]\n",
    "     Coords[global_count+7][:] = [iosx+v_vec[7,0],iosy+v_vec[7,1],iosz+v_vec[7,2]]\n",
    "     Coords[global_count+8][:] = [iosx+v_vec[8,0],iosy+v_vec[8,1],iosz+v_vec[8,2]]\n",
    "     Coords[global_count+9][:] = [iosx+v_vec[9,0],iosy+v_vec[9,1],iosz+v_vec[9,2]]\n",
    "         \n",
    "     return \n",
    "      \n",
    "\n",
    "def SLM_d(pvecs,iosx,iosy,iosz,Coords,global_count):\n",
    "     b_vec = np.zeros([9,3])          \n",
    "     b_vec[:] = pvecs\n",
    "     \n",
    "     v_vec = np.zeros([9,3])\n",
    "     \n",
    "     masses = masses_SLM\n",
    "     totmass = sum(masses)\n",
    "        \n",
    "     v_vec[0,0] = -((b_vec[0,0])*masses[0]+(b_vec[0,0]+b_vec[1,0])*masses[1]+(b_vec[0,0]+b_vec[2,0]+b_vec[1,0])*masses[3]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0])*masses[2]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[4,0])*masses[4]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[5,0])*masses[5]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[5,0]+b_vec[6,0])*masses[6]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[5,0]+b_vec[7,0])*masses[7]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[5,0]+b_vec[8,0])*masses[8])/totmass  + b_vec[0,0]\n",
    "     v_vec[0,1] = -((b_vec[0,1])*masses[0]+(b_vec[0,1]+b_vec[1,1])*masses[1]+(b_vec[0,1]+b_vec[2,1]+b_vec[1,1])*masses[3]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1])*masses[2]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[4,1])*masses[4]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[5,1])*masses[5]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[5,1]+b_vec[6,1])*masses[6]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[5,1]+b_vec[7,1])*masses[7]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[5,1]+b_vec[8,1])*masses[8])/totmass  + b_vec[0,1]\n",
    "     v_vec[0,2] = -((b_vec[0,2])*masses[0]+(b_vec[0,2]+b_vec[1,2])*masses[1]+(b_vec[0,2]+b_vec[2,2]+b_vec[1,2])*masses[3]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2])*masses[2]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[4,2])*masses[4]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[5,2])*masses[5]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[5,2]+b_vec[6,2])*masses[6]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[5,2]+b_vec[7,2])*masses[7]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[5,2]+b_vec[8,2])*masses[8])/totmass  + b_vec[0,2]\n",
    "    \n",
    "     v_vec[1,0] = v_vec[0,0] + b_vec[1,0]\n",
    "     v_vec[1,1] = v_vec[0,1] + b_vec[1,1]\n",
    "     v_vec[1,2] = v_vec[0,2] + b_vec[1,2]\n",
    "     \n",
    "     v_vec[3,0] = v_vec[1,0] + b_vec[2,0]\n",
    "     v_vec[3,1] = v_vec[1,1] + b_vec[2,1]\n",
    "     v_vec[3,2] = v_vec[1,2] + b_vec[2,2]\n",
    "     \n",
    "     v_vec[2,0] = v_vec[1,0] + b_vec[3,0]\n",
    "     v_vec[2,1] = v_vec[1,1] + b_vec[3,1]\n",
    "     v_vec[2,2] = v_vec[1,2] + b_vec[3,2]\n",
    "     \n",
    "     v_vec[4,0] = v_vec[2,0] + b_vec[4,0] \n",
    "     v_vec[4,1] = v_vec[2,1] + b_vec[4,1] \n",
    "     v_vec[4,2] = v_vec[2,2] + b_vec[4,2] \n",
    "          \n",
    "     v_vec[5,0] = v_vec[2,0] + b_vec[5,0] \n",
    "     v_vec[5,1] = v_vec[2,1] + b_vec[5,1] \n",
    "     v_vec[5,2] = v_vec[2,2] + b_vec[5,2] \n",
    "        \n",
    "     v_vec[6,0] = v_vec[5,0] + b_vec[6,0] \n",
    "     v_vec[6,1] = v_vec[5,1] + b_vec[6,1] \n",
    "     v_vec[6,2] = v_vec[5,2] + b_vec[6,2] \n",
    " \n",
    "     v_vec[7,0] = v_vec[5,0] + b_vec[7,0] \n",
    "     v_vec[7,1] = v_vec[5,1] + b_vec[7,1] \n",
    "     v_vec[7,2] = v_vec[5,2] + b_vec[7,2] \n",
    "\n",
    "     v_vec[8,0] = v_vec[5,0] + b_vec[8,0] \n",
    "     v_vec[8,1] = v_vec[5,1] + b_vec[8,1] \n",
    "     v_vec[8,2] = v_vec[5,2] + b_vec[8,2] \n",
    "     \n",
    "\n",
    "     Coords[global_count][:] = [iosx+v_vec[0,0],iosy+v_vec[0,1],iosz+v_vec[0,2]]\n",
    "     Coords[global_count+1][:] = [iosx+v_vec[1,0],iosy+v_vec[1,1],iosz+v_vec[1,2]]\n",
    "     Coords[global_count+2][:] = [iosx+v_vec[2,0],iosy+v_vec[2,1],iosz+v_vec[2,2]]\n",
    "     Coords[global_count+3][:] = [iosx+v_vec[3,0],iosy+v_vec[3,1],iosz+v_vec[3,2]]\n",
    "     Coords[global_count+4][:] = [iosx+v_vec[4,0],iosy+v_vec[4,1],iosz+v_vec[4,2]]\n",
    "     Coords[global_count+5][:] = [iosx+v_vec[5,0],iosy+v_vec[5,1],iosz+v_vec[5,2]]\n",
    "     Coords[global_count+6][:] = [iosx+v_vec[6,0],iosy+v_vec[6,1],iosz+v_vec[6,2]]\n",
    "     Coords[global_count+7][:] = [iosx+v_vec[7,0],iosy+v_vec[7,1],iosz+v_vec[7,2]]\n",
    "     Coords[global_count+8][:] = [iosx+v_vec[8,0],iosy+v_vec[8,1],iosz+v_vec[8,2]]\n",
    "          \n",
    "     return \n",
    "      \n",
    "\n",
    "def SLE_d(pvecs,iosx,iosy,iosz,Coords,global_count):\n",
    "     b_vec = np.zeros([11,3])          \n",
    "     b_vec[:] = pvecs\n",
    "     \n",
    "     v_vec = np.zeros([11,3])\n",
    "     \n",
    "     masses = masses_SLE\n",
    "     totmass = sum(masses)\n",
    "        \n",
    "     v_vec[0,0] = -((b_vec[0,0])*masses[0]+(b_vec[0,0]+b_vec[1,0])*masses[1]+(b_vec[0,0]+b_vec[2,0]+b_vec[1,0])*masses[3]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0])*masses[2]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[4,0])*masses[4]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[5,0])*masses[5]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[7,0])*masses[7]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[5,0]+b_vec[6,0])*masses[6]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[7,0]+b_vec[8,0])*masses[8]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[7,0]+b_vec[9,0])*masses[9]+(b_vec[0,0]+b_vec[1,0]+b_vec[3,0]+b_vec[7,0]+b_vec[10,0])*masses[10])/totmass + b_vec[0,0]  \n",
    "     v_vec[0,1] = -((b_vec[0,1])*masses[0]+(b_vec[0,1]+b_vec[1,1])*masses[1]+(b_vec[0,1]+b_vec[2,1]+b_vec[1,1])*masses[3]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1])*masses[2]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[4,1])*masses[4]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[5,1])*masses[5]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[7,1])*masses[7]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[5,1]+b_vec[6,1])*masses[6]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[7,1]+b_vec[8,1])*masses[8]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[7,1]+b_vec[9,1])*masses[9]+(b_vec[0,1]+b_vec[1,1]+b_vec[3,1]+b_vec[7,1]+b_vec[10,1])*masses[10])/totmass + b_vec[0,1]\n",
    "     v_vec[0,2] = -((b_vec[0,2])*masses[0]+(b_vec[0,2]+b_vec[1,2])*masses[1]+(b_vec[0,2]+b_vec[2,2]+b_vec[1,2])*masses[3]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2])*masses[2]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[4,2])*masses[4]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[5,2])*masses[5]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[7,2])*masses[7]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[5,2]+b_vec[6,2])*masses[6]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[7,2]+b_vec[8,2])*masses[8]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[7,2]+b_vec[9,2])*masses[9]+(b_vec[0,2]+b_vec[1,2]+b_vec[3,2]+b_vec[7,2]+b_vec[10,2])*masses[10])/totmass + b_vec[0,2]\n",
    "     \n",
    "     v_vec[1,0] = v_vec[0,0] + b_vec[1,0]\n",
    "     v_vec[1,1] = v_vec[0,1] + b_vec[1,1]\n",
    "     v_vec[1,2] = v_vec[0,2] + b_vec[1,2]\n",
    "     \n",
    "     v_vec[3,0] = v_vec[1,0] + b_vec[2,0]\n",
    "     v_vec[3,1] = v_vec[1,1] + b_vec[2,1]\n",
    "     v_vec[3,2] = v_vec[1,2] + b_vec[2,2]\n",
    "     \n",
    "     v_vec[2,0] = v_vec[1,0] + b_vec[3,0]\n",
    "     v_vec[2,1] = v_vec[1,1] + b_vec[3,1]\n",
    "     v_vec[2,2] = v_vec[1,2] + b_vec[3,2]\n",
    "     \n",
    "     v_vec[4,0] = v_vec[2,0] + b_vec[4,0] \n",
    "     v_vec[4,1] = v_vec[2,1] + b_vec[4,1] \n",
    "     v_vec[4,2] = v_vec[2,2] + b_vec[4,2] \n",
    "          \n",
    "     v_vec[5,0] = v_vec[2,0] + b_vec[5,0] \n",
    "     v_vec[5,1] = v_vec[2,1] + b_vec[5,1] \n",
    "     v_vec[5,2] = v_vec[2,2] + b_vec[5,2] \n",
    "        \n",
    "     v_vec[6,0] = v_vec[5,0] + b_vec[6,0] \n",
    "     v_vec[6,1] = v_vec[5,1] + b_vec[6,1] \n",
    "     v_vec[6,2] = v_vec[5,2] + b_vec[6,2] \n",
    " \n",
    "     v_vec[7,0] = v_vec[2,0] + b_vec[7,0] \n",
    "     v_vec[7,1] = v_vec[2,1] + b_vec[7,1] \n",
    "     v_vec[7,2] = v_vec[2,2] + b_vec[7,2] \n",
    "\n",
    "     v_vec[8,0] = v_vec[7,0] + b_vec[8,0] \n",
    "     v_vec[8,1] = v_vec[7,1] + b_vec[8,1] \n",
    "     v_vec[8,2] = v_vec[7,2] + b_vec[8,2] \n",
    "\n",
    "     v_vec[9,0] = v_vec[7,0] + b_vec[9,0] \n",
    "     v_vec[9,1] = v_vec[7,1] + b_vec[9,1] \n",
    "     v_vec[9,2] = v_vec[7,2] + b_vec[9,2] \n",
    "\n",
    "     v_vec[10,0] = v_vec[7,0] + b_vec[10,0] \n",
    "     v_vec[10,1] = v_vec[7,1] + b_vec[10,1] \n",
    "     v_vec[10,2] = v_vec[7,2] + b_vec[10,2] \n",
    "     \n",
    "     Coords[global_count][:] = [iosx+v_vec[0,0],iosy+v_vec[0,1],iosz+v_vec[0,2]]\n",
    "     Coords[global_count+1][:] = [iosx+v_vec[1,0],iosy+v_vec[1,1],iosz+v_vec[1,2]]\n",
    "     Coords[global_count+2][:] = [iosx+v_vec[2,0],iosy+v_vec[2,1],iosz+v_vec[2,2]]\n",
    "     Coords[global_count+3][:] = [iosx+v_vec[3,0],iosy+v_vec[3,1],iosz+v_vec[3,2]]\n",
    "     Coords[global_count+4][:] = [iosx+v_vec[4,0],iosy+v_vec[4,1],iosz+v_vec[4,2]]\n",
    "     Coords[global_count+5][:] = [iosx+v_vec[5,0],iosy+v_vec[5,1],iosz+v_vec[5,2]]\n",
    "     Coords[global_count+6][:] = [iosx+v_vec[6,0],iosy+v_vec[6,1],iosz+v_vec[6,2]]\n",
    "     Coords[global_count+7][:] = [iosx+v_vec[7,0],iosy+v_vec[7,1],iosz+v_vec[7,2]]\n",
    "     Coords[global_count+8][:] = [iosx+v_vec[8,0],iosy+v_vec[8,1],iosz+v_vec[8,2]]\n",
    "     Coords[global_count+9][:] = [iosx+v_vec[9,0],iosy+v_vec[9,1],iosz+v_vec[9,2]]\n",
    "     Coords[global_count+10][:] = [iosx+v_vec[10,0],iosy+v_vec[10,1],iosz+v_vec[10,2]]\n",
    "          \n",
    "     return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d64d3",
   "metadata": {},
   "source": [
    "### Get the structure of each chain <span id='n'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e5ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mer_identity(inp):  \n",
    "  shiftx = 60\n",
    "  identities = []\n",
    "  names = []\n",
    "  names_gro = []\n",
    "  SLS_names = [\"O1s\",\"C2s\",\"C3s\",\"O4s\",\"H5s\",\"H10s\",\"C6s\",\"H7s\",\"H8s\",\"H9s\"]\n",
    "  SLMD_names = [\"O1d\",\"C2d\",\"C3d\",\"O4d\",\"H5d\",\"C6d\",\"H7d\",\"H8d\",\"H9d\"]\n",
    "  SLML_names = [\"O1l\",\"C2l\",\"C3l\",\"O4l\",\"H5l\",\"C6l\",\"H7l\",\"H8l\",\"H9l\"]\n",
    "  SLE_names = [\"O1e\",\"C2e\",\"C3e\",\"O4e\",\"H5e\",\"O10e\",\"H11e\",\"C6e\",\"H7e\",\"H8e\",\"H9e\"]   \n",
    "  \n",
    "  SLS_names_gro = [\"O1\",\"C2\",\"C3\",\"O4\",\"H5\",\"H10\",\"C6\",\"H7\",\"H8\",\"H9\"]\n",
    "  SLM_names_gro = [\"O1\",\"C2\",\"C3\",\"O4\",\"H5\",\"C6\",\"H7\",\"H8\",\"H9\"]\n",
    "  SLE_names_gro = [\"O1\",\"C2\",\"C3\",\"O4\",\"H5\",\"O10\",\"H11\",\"C6\",\"H7\",\"H8\",\"H9\"]\n",
    "  for j in range(inp.shape[0]):\n",
    "   for i in range(shiftx+1,inp.shape[1]-shiftx-3,9):\n",
    "      if inp[j][i,-1]==1 :\n",
    "          identities.append(int(0))\n",
    "          names += SLS_names\n",
    "          names_gro += SLS_names_gro \n",
    "      elif inp[j][i,-2]==1:  \n",
    "          identities.append(int(1))\n",
    "          names += SLMD_names\n",
    "          names_gro += SLM_names_gro\n",
    "      elif inp[j][i,-3]==1:  \n",
    "          identities.append(int(2))\n",
    "          names += SLML_names\n",
    "          names_gro += SLM_names_gro      \n",
    "      elif inp[j][i,-4]==1:  \n",
    "          identities.append(int(3))\n",
    "          names += SLE_names\n",
    "          names_gro += SLE_names_gro\n",
    "  frame_nmer = len(identities)    \n",
    "  return identities, shiftx, frame_nmer, names, names_gro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77e12a",
   "metadata": {},
   "source": [
    "### Re-insert atomic detail to CG congigurations via the trained CNN <span id='o'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d83a33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chains(frame_idx,epoch,save_path,inp,tar,box):\n",
    "  print(frame_idx,epoch)\n",
    "\n",
    "  Pcoords = np.zeros([int(npart),3],dtype=np.float64)\n",
    "  Tcoords = np.zeros([int(npart),3],dtype=np.float64)\n",
    "  \n",
    "  Pst = open(save_path+'PStart_'+str(com_list[frame_idx])+'.gro', 'w')\n",
    "  Pst.write(\"PLA\\n\")\n",
    "  Pst.write(str(npart)+\"\\n\")\n",
    "    \n",
    "  pstd = open(save_path+\"PStart_\"+str(com_list[frame_idx])+'.dat', 'w')\n",
    "  pstd.write(\"PLA\\n\")\n",
    "  pstd.write(str(npart)+'\\n')\n",
    "     \n",
    "  Tst = open(save_path+'TStart_'+str(com_list[frame_idx])+'.gro', 'w')\n",
    "  Tst.write(\"PLA\\n\")\n",
    "  Tst.write(str(npart)+\"\\n\")\n",
    "    \n",
    "  tstd = open(save_path+\"TStart_\"+str(com_list[frame_idx])+'.dat', 'w')\n",
    "  tstd.write(\"PLA\\n\")\n",
    "  tstd.write(str(npart)+'\\n')     \n",
    "  identities, shiftx, frame_nmer, frame_names, frame_names_gro = mer_identity(inp) \n",
    "  if epoch<10:\n",
    "      checkpoint_path = \"./tmp/cp-000\"+ str(epoch)+ \".ckpt\"\n",
    "  elif epoch<100 and epoch>=10:    \n",
    "      checkpoint_path = \"./tmp/cp-00\"+ str(epoch)+ \".ckpt\"\n",
    "  elif epoch<1000 and epoch>=100:    \n",
    "      checkpoint_path = \"./tmp/cp-0\"+ str(epoch)+ \".ckpt\"\n",
    "  else:    \n",
    "      checkpoint_path = \"./tmp/cp-\"+ str(epoch)+ \".ckpt\"\n",
    "\n",
    "  model.built = True  \n",
    "  model.load_weights(checkpoint_path) \n",
    "  pred = model.generator.predict(inp)\n",
    "  \n",
    "  pred += 1\n",
    "  pred /= 2.\n",
    "  pred *= 0.153001*2\n",
    "  pred += -0.153001   \n",
    "  PartIndx = 0  \n",
    "  c = 0    \n",
    "  for ii in range(frame_nmer):              \n",
    "        sample_idx = ii//nmer       \n",
    "        cg_idx = c+shiftx+1\n",
    "       \n",
    "        iosx=float(inp[sample_idx][cg_idx,0])\n",
    "        iosy=float(inp[sample_idx][cg_idx,1])\n",
    "        iosz=float(inp[sample_idx][cg_idx,2])\n",
    "        \n",
    "        i = shiftx+c\n",
    "\n",
    "        if identities[ii]==0: \n",
    "            spots=spots_SLS  \n",
    "            pos=np.zeros([spots,3],dtype=np.float64)\n",
    "            tos=np.zeros([spots,3],dtype=np.float64)\n",
    "            pos[:] = pred[sample_idx][i:i+spots]\n",
    "            tos[:] = tar[sample_idx][i:i+spots]\n",
    "            SLS_d(pos,iosx,iosy,iosz,Pcoords,PartIndx)\n",
    "            SLS_d(tos,iosx,iosy,iosz,Tcoords,PartIndx)\n",
    "            PartIndx += merlen_SLS            \n",
    "        elif identities[ii]==3: \n",
    "            spots=spots_SLE  \n",
    "            pos=np.zeros([spots,3],dtype=np.float64)\n",
    "            tos=np.zeros([spots,3],dtype=np.float64)\n",
    "            pos[:] = pred[sample_idx][i:i+spots]\n",
    "            tos[:] = tar[sample_idx][i:i+spots]\n",
    "            SLE_d(pos,iosx,iosy,iosz,Pcoords,PartIndx)\n",
    "            SLE_d(tos,iosx,iosy,iosz,Tcoords,PartIndx)\n",
    "            PartIndx += merlen_SLE\n",
    "        elif identities[ii]==1: \n",
    "            spots=spots_SLM  \n",
    "            # print(PartIndx, ii,spots,c) \n",
    "            pos=np.zeros([spots,3],dtype=np.float64)\n",
    "            tos=np.zeros([spots,3],dtype=np.float64)\n",
    "            pos[:] = pred[sample_idx][i:i+spots]\n",
    "            tos[:] = tar[sample_idx][i:i+spots]\n",
    "            SLM_d(pos,iosx,iosy,iosz,Pcoords,PartIndx)\n",
    "            SLM_d(tos,iosx,iosy,iosz,Tcoords,PartIndx)\n",
    "            \n",
    "            PartIndx += merlen_SLM\n",
    "        elif identities[ii]==2: \n",
    "            spots=spots_SLM  \n",
    "            # print(PartIndx, ii,spots,c) \n",
    "            pos=np.zeros([spots,3],dtype=np.float64)\n",
    "            tos=np.zeros([spots,3],dtype=np.float64)\n",
    "            pos[:] = pred[sample_idx][i:i+spots]\n",
    "            tos[:] = tar[sample_idx][i:i+spots]\n",
    "            SLM_d(pos,iosx,iosy,iosz,Pcoords,PartIndx)\n",
    "            SLM_d(tos,iosx,iosy,iosz,Tcoords,PartIndx)\n",
    "            \n",
    "            PartIndx += merlen_SLM    \n",
    "        c += spots \n",
    "\n",
    "        if PartIndx%chainlen==0:\n",
    "            c = 0 # initialize for every new sample \n",
    "    \n",
    "        \n",
    "  for j in range(Pcoords.shape[0]):\n",
    "         chain_idx = j//(chainlen)\n",
    "         Pst.write('%5d%5s%5s%5s%8.3f%8.3f%8.3f  0.0000  0.0000  0.0000\\n'%((chain_idx+1,'PB',str(frame_names_gro[j]),str(j+1)[-5:],Pcoords[j][0],Pcoords[j][1],Pcoords[j][2]))) \n",
    "         print(str(frame_names[j]),Pcoords[j][0],Pcoords[j][1],Pcoords[j][2], file=pstd)   \n",
    "         Tst.write('%5d%5s%5s%5s%8.3f%8.3f%8.3f  0.0000  0.0000  0.0000\\n'%((chain_idx+1,'PB',str(frame_names_gro[j]),str(j+1)[-5:],Tcoords[j][0],Tcoords[j][1],Tcoords[j][2]))) \n",
    "         print(str(frame_names[j]),Tcoords[j][0],Tcoords[j][1],Tcoords[j][2], file=tstd)   \n",
    "\n",
    "  Pst.write('%10.5f%10.5f%10.5f\\n'%(( box[0] ,box[1] , box[2] )))\n",
    "  Pst.close\n",
    "  pstd.close\n",
    "  Tst.write('%10.5f%10.5f%10.5f\\n'%(( box[0] , box[1] , box[2])))\n",
    "  Tst.close\n",
    "  tstd.close\n",
    "  return   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c30da",
   "metadata": {},
   "source": [
    "### Prediction of an atomistic configuration from a given CG configuration <span id='p'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6f0db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "save_path=\"./Data\"+\"_\"+str(EPOCHS)+\"/\"       \n",
    "os.mkdir(save_path)\n",
    "create_chains(test_frame,EPOCHS,save_path,test_input[x],test_target[x],test_boxes[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0369a61",
   "metadata": {},
   "source": [
    "# Visualize the results <span id='q'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0e1ede",
   "metadata": {},
   "source": [
    "### Generate the distribution plots for bond lengths, bond angles and dihedral angles <span id='r'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "870652f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Bond lenghts combinations:  18\n",
      "Bond angles combinations:  27\n",
      "Dihedral angles combinations:  42\n",
      "Bond lenghts combinations:  18\n",
      "Bond angles combinations:  27\n",
      "Dihedral angles combinations:  42\n",
      "2.9310450553894043\n"
     ]
    }
   ],
   "source": [
    "generate_distribution_plots(test_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
